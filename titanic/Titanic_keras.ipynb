{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving the titanic problem with a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "np.random.seed(1919)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "y = train.Survived.values\n",
    "train = train.drop(['Survived'], axis=1)\n",
    "\n",
    "\n",
    "def modify_data(base_df):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['Gender'] = base_df.Sex.map(lambda x:1 if x.lower() == 'female' else 0)\n",
    "    # apply functions to dataframe => Fare NaN\n",
    "    fares_by_class = base_df.groupby('Pclass').Fare.median()\n",
    "\n",
    "    def getFare(example):\n",
    "        if pd.isnull(example):\n",
    "            example['Fare'] = fares_by_class[example['Pclass']]\n",
    "        return example\n",
    "    new_df['Fare'] = base_df['Fare']\n",
    "    new_df['Family'] = (base_df.Parch + base_df.SibSp) > 0\n",
    "    new_df['Family'] = new_df['Family'].map(lambda x:1 if x else 0)\n",
    "    new_df['GenderFam'] = new_df['Gender']+new_df['Family']\n",
    "    new_df['Title'] = base_df.Name.map(lambda x:x.split(' ')[0])\n",
    "    new_df['Rich'] = base_df.Pclass == 1\n",
    "    return new_df\n",
    "    \n",
    "train = modify_data(train)\n",
    "\n",
    "# TEST DATA\n",
    "#test = pd.read_csv('titanic_test.csv', header=0)        # Load the test file into a dataframe\n",
    "ids = test['PassengerId'].values\n",
    "test = modify_data(test)\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "\n",
    "\n",
    "for f in train.columns:\n",
    "    if train[f].dtype=='object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))\n",
    "\n",
    "X = train.values\n",
    "dimof_input = X.shape[1]\n",
    "dimof_output = len(set(y.flat))\n",
    "y = np_utils.to_categorical(y, dimof_output)\n",
    "test_x = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple neural network with a couple of dense layers.  The *hidden_sizes* list defines the hidden layers, in this case 2 hidden layers of 200 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "hidden_sizes = [200, 200]\n",
    "dropout = 0.5\n",
    "countof_epoch = 200\n",
    "verbose = 0\n",
    "\n",
    "model = Sequential()\n",
    "for i, s in enumerate(hidden_sizes):\n",
    "    if i:\n",
    "        model.add(Dense(s))\n",
    "    else:\n",
    "        model.add(Dense(s, input_shape=(dimof_input,)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "model.add(Dense(dimof_output))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss: ', 0.45977673917908457)\n",
      "('accuracy: ', 0.79685746352413023)\n",
      "()\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X, y,\n",
    "    show_accuracy=True, #validation_split=0.2,\n",
    "    batch_size=batch_size, nb_epoch=countof_epoch, verbose=verbose)\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X, y, show_accuracy=True, verbose=verbose)\n",
    "print('loss: ', loss)\n",
    "print('accuracy: ', accuracy)\n",
    "print()\n",
    "predict_x = test_x\n",
    "predict_df = test\n",
    "preds = model.predict(predict_x, batch_size=batch_size)\n",
    "pred_arr = [p[0] for p in preds]\n",
    "results = pd.DataFrame({\"PassengerId\":ids, 'Survived': pred_arr})\n",
    "results['PassengerId'] = results['PassengerId'].astype('int')\n",
    "results.Survived = results.Survived.map(lambda x:0 if x >= 0.5 else 1)\n",
    "results.set_index(\"PassengerId\")\n",
    "print results.Survived.sum()\n",
    "results.to_csv('results_nn.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
