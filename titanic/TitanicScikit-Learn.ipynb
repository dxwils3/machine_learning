{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses various models from scikit-learn to produce a soltion for the [kaggle Titanic](https://www.kaggle.com/c/titanic) problem.  It's worth observing that none of these methods seemed to produce a good solution to the Titanic problem, with accuracy rates being generally in the low 70% range.  The best solution I had was using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, RandomTreesEmbedding, BaggingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, LinearSVR, NuSVC, NuSVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, ExtraTreeClassifier, ExtraTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method modify_data below is used to do some feature management in a pandas DataFrame.  We create a new DataFrame keeping only the features we want to build our decision models from.  I played around with this for a while, and this set of features just represents the place I stopped, not necessarily what worked the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_data(base_df):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['Gender'] = base_df.Sex.map(lambda x:1 if x.lower() == 'female' else 0)\n",
    "    fares_by_class = base_df.groupby('Pclass').Fare.median()\n",
    "\n",
    "    def getFare(example):\n",
    "        if pd.isnull(example):\n",
    "            example['Fare'] = fares_by_class[example['Pclass']]\n",
    "        return example\n",
    "    new_df['Fare'] = base_df['Fare']\n",
    "\n",
    "    new_df['Family'] = (base_df.Parch + base_df.SibSp) > 0\n",
    "    new_df['Family'] = new_df['Family'].map(lambda x:1 if x else 0)\n",
    "    new_df['GenderFam'] = new_df['Gender']+new_df['Family']\n",
    "    new_df['Title'] = base_df.Name.map(lambda x:x.split(' ')[0])\n",
    "    new_df['Rich'] = base_df.Pclass == 1\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test data and run it through modify_data.  *y* contains the know correct values for the training data, and `ids` are passenger ids needed for submission.\n",
    "\n",
    "The *fillna* method replaces all the unknown values in the data.\n",
    "\n",
    "Finally, the *for* loop just replaces any non-numeric values with numeric identifiers.  The *Title* field will contain things like *Mr.*, *Mrs.*, and *Dr.* which will be translated to numeric values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "y = train.Survived.values\n",
    "ids = test['PassengerId'].values\n",
    "\n",
    "train = modify_data(train)\n",
    "test = modify_data(test)\n",
    "\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "for f in train.columns:\n",
    "    if train[f].dtype=='object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the models we'll use.  Notice that it's basically a trivial operation to add  anew one in.  I did a small bit of parameter tuning for the first 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = {'xgb': xgb.XGBClassifier(n_estimators=2700,\n",
    "                                   nthread=-1,\n",
    "                                   max_depth=12,\n",
    "                                   learning_rate=0.09,\n",
    "                                   silent=True,\n",
    "                                   subsample=0.8,\n",
    "                                   colsample_bytree=0.75),\n",
    "          'rf': RandomForestClassifier(n_estimators = 150, criterion='gini'),\n",
    "          'linearsvc': LinearSVC(C=0.13, loss='hinge'),\n",
    "          'linearsvr': LinearSVR(),\n",
    "          'nusvc': NuSVC(),\n",
    "          'nusvr': NuSVR(),\n",
    "          'dtc': DecisionTreeClassifier(),\n",
    "          'dtr': DecisionTreeRegressor(),\n",
    "          'etc': ExtraTreeClassifier(),\n",
    "          'etr': ExtraTreeRegressor(),\n",
    "          'rfr': RandomForestRegressor(),\n",
    "          'bc': BaggingClassifier(),\n",
    "          'lr': LinearRegression(),\n",
    "          'logit': LogisticRegression()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll just run the data through our models.\n",
    "\n",
    "We use [cross validation](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) as a means to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit 0.778900112233\n",
      "bc 0.775533108866\n",
      "xgb 0.771043771044\n",
      "etr -0.0606492121107\n",
      "rfr 0.272400656737\n",
      "linearsvc 0.712682379349\n",
      "nusvr -0.00548259448359\n",
      "dtc 0.749719416386\n",
      "nusvc 0.627384960718\n",
      "etc 0.742985409652\n",
      "rf 0.786756453423\n",
      "linearsvr 0.0489797499464\n",
      "lr 0.330374393784\n",
      "dtr -0.0186236585442\n"
     ]
    }
   ],
   "source": [
    "model_scores = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, train, y, cv=3)\n",
    "    model_scores[name] = scores.mean()\n",
    "    print(name, model_scores[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is just printing results.  The only interesting thing here is that I created a basic ensemble from the above models in which each \"good\" model gets a vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_array = []\n",
    "for m, score in model_scores.items():\n",
    "    if score < 0.76:\n",
    "        continue\n",
    "    model = models[m].fit(train, y)\n",
    "    preds = model.predict(test)\n",
    "    pred_array.append(preds)\n",
    "    results = pd.DataFrame({\"PassengerId\":ids, 'Survived': preds})\n",
    "    results['PassengerId'] = results['PassengerId'].astype('int')\n",
    "    results.set_index(\"PassengerId\")\n",
    "    results.to_csv('output/test_results_{}.csv'.format(m), index=False)\n",
    "\n",
    "ensemble_preds = [0]*len(ids)\n",
    "for p in pred_array:\n",
    "    if not ensemble_preds:\n",
    "        ensemble_preds = p\n",
    "    else:\n",
    "        ensemble_preds = [a+b for a, b in zip(ensemble_preds, p)]\n",
    "\n",
    "votes = [0 if a < len(pred_array)/2 else 1 for a in ensemble_preds]\n",
    "results = pd.DataFrame({\"PassengerId\":ids, 'Survived': votes})\n",
    "results['PassengerId'] = results['PassengerId'].astype('int')\n",
    "results.set_index(\"PassengerId\")\n",
    "results.to_csv('output/test_results_ensemble.csv'.format(m), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
